# -*- coding: utf-8 -*-
"""Get_Tweets.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fxSDGuKsKaIloRKGrwDEaDv3CDy-R-bM
"""

#!pip install tweepy

# This will create a dataframe with coloumn (image_url, account_name, and tweet_text), Aur bhi column add kr sakte hain apan.
import tweepy
import csv
import pandas as pd
import sys

import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

import torch
import torchvision
import tarfile
from torchvision.datasets.utils import download_url
from torch.utils.data import random_split
import numpy as np
from torchvision.datasets import ImageFolder
from torchvision.transforms import ToTensor, ToPILImage
import torchvision.transforms as tt
import PIL
from imgaug import augmenters as iaa
import imgaug as ia
import cv2 as cv
import math
import argparse
from facenet_pytorch.models.mtcnn import MTCNN
import matplotlib.pyplot as plt
from PIL import Image
import pandas as pd
from efficientnet_pytorch import EfficientNet
import torch.nn as nn
import torch.nn.functional as F
from torch import functional as Func
import PIL
from imgaug import augmenters as iaa
import cv2
import glob
import re
import moviepy.editor as moviepy
from facenet_pytorch.models.mtcnn import MTCNN
from tqdm.notebook import tqdm
import albumentations as A
from albumentations.pytorch import ToTensorV2
from fastbook import *
from fastai.vision import *
from fastai import *
import pathlib
from fastai.vision.all import *
from torchvision import transforms as t_2
from matplotlib import pyplot
import warnings
import resnet50_vit_model
from resnet50_vit_model import VIT, PatchEmbedding, multiHeadAttention, residual, mlp, TransformerBlock, Transformer, \
    Classification
from torch.autograd import Variable
import os
from werkzeug.utils import secure_filename
from flask import Flask, flash, request, redirect, send_file, render_template
import requests
import download_video
import util
from PIL import Image
from PIL.ExifTags import TAGS
import os

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
warnings.filterwarnings("ignore")

UPLOAD_FOLDER = os.path.join('static', 'videos')
MY_UPLOAD_FOLDER = os.path.join('uploaded')
Fake_Folder_d_4 = os.path.join('static', 'videos')
UPLOAD_IMAGE_FOLDER = os.path.join('static', 'Full Images')
UPLOAD_FACE_FOLDER = os.path.join('static', 'test_images')
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0
app.config["MY_UPLOAD_FOLDER"] = MY_UPLOAD_FOLDER


# API credentials here
consumer_key = 'AxOyrvs5TfCwW4zMC6FiQVijO'
consumer_secret = '68LVeWzJJOHxIYHZ0BZnKKvlvyLlgEVWoJzxQRPgiTgi2oKMEk'
access_token = '1292791929810423810-uf31LSiTTMMtLThOM12nZXZ1sMXXYT'
access_token_secret = 'n0cOgdGm1PslPx9I4IsfpiyY0yLWS6ZwXHNXdKrqLgP0S'

auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
#api = tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)
api = tweepy.API(auth,wait_on_rate_limit=True)

 
HashValue = "Deepfake"

StartDate = "2022-02-15"

# getting the search word/hashtag and date range from user
#HashValue = input("Enter the hashtag you want the tweets to be downloaded for: ")
#StartDate = input("Enter the start date in this format yyyy-mm-dd: ")

# Open/Create a file to append data
csvFile = open(HashValue+'.csv', 'a')

#Use csv Writer
csvWriter = csv.writer(csvFile)
df = pd.DataFrame(columns = ['image_url', 'account_name','text_on_tweet', ])

for tweet in tweepy.Cursor(api.search_tweets,q=HashValue,count=20,lang="en",since=StartDate, tweet_mode='extended', retry_count = 5, retry_delay = 5, include_entities=True).items(200):
  if 'media' in tweet.entities:
        for image in  tweet.entities['media']:
            #print(image['media_url'],tweet.user.screen_name, tweet.full_text.encode('utf-8') )
            df = df.append({'image_url' : image['media_url'] , 'account_name' : tweet.user.screen_name , 'text_on_tweet' : tweet.full_text.encode('utf-8')}, ignore_index = True)
  #csvWriter.writerow([tweet.created_at,tweet.user.location,tweet.user.screen_name,tweet.user.verified,tweet.full_text.encode('utf-8')])
  
  
   
  #print(tweet.created_at, tweet.user.location, tweet.user.screen_name, tweet.user.verified,tweet.full_text)
  #csvWriter.writerow([tweet.created_at,tweet.user.location,tweet.user.screen_name,tweet.user.verified,tweet.full_text.encode('utf-8')])

#print ("Scraping finished and saved to "+HashValue+".csv")
#sys.exit()

### Library to download image from internet
#!pip install wget

print(df)

print(df["image_url"])

print(df["account_name"])

#Uske baad apan image_url ko access krenge and wget use krke image download kr lenge 

import wget
import cv2

##############################

class ImgAugTransform:
    """Test-Time Transformations"""

    def __init__(self):
        self.aug = iaa.Sequential([
            iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 3.0))),
            iaa.Fliplr(0.5),
            iaa.Affine(rotate=(-20, 20), mode='symmetric'),
            iaa.Sometimes(0.25,
                          iaa.OneOf([iaa.Dropout(p=(0, 0.1)),
                                     iaa.CoarseDropout(0.1, size_percent=0.5)])),
            iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)
        ])

    def __call__(self, img):
        img = np.array(img)
        return self.aug.augment_image(img)


transforms = ImgAugTransform()

stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
transforms = torchvision.transforms.Compose([
    ImgAugTransform(),
    lambda x: PIL.Image.fromarray(x),
    torchvision.transforms.RandomVerticalFlip(),
    tt.RandomHorizontalFlip(),
    tt.RandomResizedCrop((224, 224), interpolation=2),
    tt.ToTensor(),
    tt.Normalize(*stats, inplace=True)
])

test_tfms = transforms

aug_6 = A.Compose({A.RandomResizedCrop(224, 224)})

##########################################################################################################

"""GPU Handling"""


def get_default_device():
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')


def to_device(data, device):
    """Move tensor(s) to chosen device"""
    if isinstance(data, (list, tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)


class DeviceDataLoader():
    """Wrap a dataloader to move data to a device"""

    def __init__(self, dl, device):
        self.dl = dl
        self.device = device

    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl:
            yield to_device(b, self.device)

    def __len__(self):
        """Number of batches"""
        return len(self.dl)


device = get_default_device()

model_4 = torch.load("29_d56.pth", map_location=device)
model_4.to(device)  # Put Model on CPU or GPU
model_4.eval()  # Put Model into Evaluation Mode

model_5 = torch.load("model_2.pth", map_location=device)
model_5.to(device)  # Put Model on CPU or GPU
model_5.eval()  # Put Model into Evaluation Mode

model_6 = torch.load(os.path.join("Trained_Models", "Fake_Face_Detection_Model.pth"), map_location=device)
model_6.to(device)
model_6.eval()

model_7 = torch.load(os.path.join("Trained_Models", "Resnet_VIT_Updated_New_F1.pth"), map_location=device)
model_7.to(device)
model_7.eval()


def get_my_x(fname:Path): pass

def get_my_y(fname:Path):
    pass


def acc_camvid(*_): pass

def get_y(*_): pass


###################################


global findings,scores,path

findings = []
scores = []
path = []

##########Added######################
def convertImageToTensor(final_image):
    image_transforms = tt.Compose([
        tt.Resize((384, 384)),
        tt.ToTensor(),
        tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)
    ])
    image = Image.open(final_image)
    imageTensor = image_transforms(image).float()
    imageTensor = Variable(imageTensor, requires_grad=False)
    imageTensor = imageTensor.unsqueeze(0)  # converted in the form of batch
    return imageTensor


####################################






def Fake_Face(image_filename, crop=True, model_number=7):
    #filename = 'fimt.' + filename.split(".")[-1]
    print("function file name: ", image_filename)
    d21 = 0
    # final_image = os.path.join(UPLOAD_FACE_FOLDER, filename)
    #print(os.path.join(UPLOAD_IMAGE_FOLDER, filename))
    #final_image = os.path.join(UPLOAD_IMAGE_FOLDER, filename)


    #print("FAKE_FACE FUNCTION", image)

    frame_4 = cv2.imread(image_filename)  # Load Image
    # print("frame_4 = ")
    # print(frame_4)

    mtcnn = MTCNN(keep_all=True, min_face_size=176, thresholds=[0.95, 0.95, 0.95],
                  device=device)  # Load Face Detector
    frame_5 = cv2.cvtColor(frame_4, cv2.COLOR_BGR2RGB)
    img2 = Image.fromarray(frame_5.astype(np.uint8))

    frame_5 = img2
    try:
        boxes, landmarks = mtcnn.detect(frame_5, landmarks=False)  # Detect Faces
        print("xyz")
        # b1 = img
    # print(boxes)
    except:
        print("Couldn't Find a Face!!!!")  # If mtcnn fails,this print statement is executed
        return -1,None,''
    #

    # Loading Model
    # model=torch.load(os.path.join("Trained_Models","Fake_Face_Detection_Model.pth"), map_location=device)

    ########Added########################
    # model_number = 6## 6 or 7  6-Fake_Face_Detection_Model, 7- Resnet50_VIT_Model
    #####################################

    ### If cropping is not required
    crop = True  ####Added
    if crop == False:

        image = plt.imread(image_filename)  #### Load Image
        image = Image.fromarray(image).convert('RGB')  #### Convert Image to RGB
        image.save("test_face_image.jpg")

        if (model_number == 6):
            image = aug_3(image=np.array(image))['image']  ##### Apply Transformations
            # original_image1 = Image.fromarray(image)
            # original_image1.save(os.path.join('test_faces_output','original_image1.jpg'))
            image = np.transpose(image, (2, 0, 1)).astype(np.float32)
            image = torch.tensor(image, dtype=torch.float)  ###### Convert Image to Tensor
            pred = model_6(image.unsqueeze(0).to(device)).argmax()  #### Pass through Model
            print("Predicted Value:", pred)

            pred1 = model_6(image.unsqueeze(0).to(device))
            print(pred1)
            if (pred == 1):
                label = "Fake"
            else:
                label = "Real"

            color = (0, 0, 255) if label == "Fake" else (0, 255, 0)

            print(label + " " + "Face Found")
            # exit()
            return label, "test_face_image.jpg"
        ############Added######################
        elif (model_number == 7):
            print("Inside model_7")
            image = convertImageToTensor(image_filename)  ##originally were sending image path
            print("Image converted")
            image = image.to(device)
            print(image.shape)
            preds = model_7(image)  # get the softmax probabilities
            #preds = preds.cpu()

            ###
            pred6 = torch.softmax(preds.squeeze(), 0)
            pred6 = pred6.cpu().detach().numpy()[0]
            ###
            pred = torch.argmax(preds, 1)[0]
            print("predicted value: 0- Fake, 1-Real", preds,"numpy val",pred6)
            if (pred == 1):
                label = "Real"
            else:
                label = "Fake"

            color = (0, 0, 255) if label == "Fake" else (0, 255, 0)

            print(label + " " + "Face Found")
            # exit()
            return label, pred6, "test_face_image.jpg"
        ###########################

    mtcnn = MTCNN(keep_all=True, min_face_size=176, thresholds=[0.85, 0.90, 0.90],
                  device=device)  # Load Face Detector
    frame = cv2.cvtColor(frame_4, cv2.COLOR_BGR2RGB)
    frame_4 = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    img = Image.fromarray(frame.astype(np.uint8))

    frame = img
    k = 0

    # Detect face
    try:
        boxes, landmarks = mtcnn.detect(frame, landmarks=False)  # Detect Faces
        b1 = img
    # print(boxes)
    except:
        print("Couldn't Find a Face!!!!")  ##### If mtcnn fails,this print statement is executed
        return -1,None,''
    ###### Loop over all faces
    try:
        for i in range(0, len(boxes)):
            #### Crop Faces from Images
            x, y, width, height = boxes[i]
            max_width, max_height = b1.size
            boxes[i][0] -= width / 10
            boxes[i][1] -= height / 10
            boxes[i][0] = max(0, boxes[i][0])
            boxes[i][1] = max(0, boxes[i][1])
            boxes[i][2] = min(boxes[i][2] + (width / 10), max_width)
            boxes[i][3] = min(boxes[i][3] + (height / 10), max_height)
            b4 = b1.crop(boxes[i])
            b4.save("test_face_image.jpg")  ##### Save Cropped Image

            if model_number == 6:
                image = plt.imread("test_face_image.jpg")  #### Read Cropped Image
                image = Image.fromarray(image).convert('RGB')  #### Convet to RGB
                image = aug_3(image=np.array(image))['image']  ##### Apply Transformations
                image = np.transpose(image, (2, 0, 1)).astype(np.float32)
                image = torch.tensor(image, dtype=torch.float)  ##### Convert to tensor
                pred = model_6(image.unsqueeze(0).to(device)).argmax()  ##### Pass thorugh The Model

                if (pred == 1):
                    label = "Fake"
                else:
                    label = "Real"

            elif model_number == 7:
                print("Inside model_7,crop=true")
                image = convertImageToTensor("test_face_image.jpg")  ##originally were sending image path
                print("Image converted")
                image = image.to(device)
                print(image.shape)
                preds = model_7(image)  # get the softmax probabilities
                #preds = preds.cpu()
                ####
                pred6 = torch.softmax(preds.squeeze(), 0)
                pred6 = pred6.cpu().detach().numpy()[0]
            
                ###
                
                
                pred = torch.argmax(preds, 1)[0]
                print("predicted value1: 0- Fake, 1-Real", preds," numpy value",pred6)
                if (pred == 1):
                    label = "Real"
                else:
                    label = "Fake"
            findings.append(label)
            scores.append(pred6)

            
            color = (0, 0, 255) if label == "Fake" else (0, 255, 0)
            print("Boxes: ", boxes)
            cv2.rectangle(frame_4, (boxes[i][0], boxes[i][1]), (boxes[i][2], boxes[i][3]), color,
                          2)  # Draw Bounding Box
            cv2.imwrite(os.path.join("test_faces_output", filename), frame_4)  ##### Save the Image
            print(label,pred6 + " "+ "Face Found")
            return label, pred6, os.path.join("test_faces_output", filename)
    
    except Exception as e:
        print("-----------------***********No Faces Found***********-----------------")
        print(e)
        #findings.append('None')
        #scores.append('Null')

        return -1,None,''

#for i in df["image_url"]:
 #   image_url = i
    image_filename = wget.download(image_url)
    print('Image Successfully Downloaded: ', image_filename)
    label, score, fake_image_path = Fake_Face(image_filename)
    print("label of twitter image:",label,"Predicted Fake Score of twitter image:",score)
    #findings.append(label)
    #scores.append(score)
    path.append(os.path.abspath(image_filename))
                #a,b,c,d,e,f,g,h,i,j,k = metadata_image(filename)

                #print("Modelbbbb",a)



                #final_image = os.path.join(UPLOAD_IMAGE_FOLDER, 'fimt.' + filename.split(".")[-1])
    '''
    if label == -1:


      # this image is for FIM
      print("Now this is FIM")
      aug_3 = A.Compose({A.Resize(255, 255)})

      temp = pathlib.PosixPath
      pathlib.PosixPath = pathlib.WindowsPath

      dice = Dice()

      learn = load_learner(os.path.join("Trained_Models", "Copy_Move_FIM.pkl"))

      original_image = plt.imread(image_filename)
      original_image = Image.fromarray(original_image).convert('RGB')  # Convet to RGB
      original_image = aug_3(image=np.array(original_image))['image']  # Apply Transformations
      original_image = Image.fromarray(original_image)
      original_image.save(os.path.join('static', 'Test_FIM', 'original_image.jpg'))

      b1 = learn.predict(os.path.join('static', 'Test_FIM', 'original_image.jpg'))
      # plt.imshow(b1[0].permute(1,2,0))
      final_mask = b1[0].permute(1, 2, 0)
      im_1 = t_2.ToPILImage()(np.uint8(final_mask))
      im_1.save(os.path.join('static', 'Test_FIM', 'final_mask_image_Copy_Move.jpg'))
                    
      learn = load_learner(os.path.join("Trained_Models", "Splicing_FIM.pkl"))
      b1 = learn.predict(os.path.join('static', 'Test_FIM', 'original_image.jpg'))
                    # plt.imshow(b1[0].permute(1,2,0))
      final_mask = b1[0].permute(1, 2, 0)
      im_2 = t_2.ToPILImage()(np.uint8(final_mask))
      im_2.save(os.path.join("static", "Test_FIM", "final_mask_image_Splicing.jpg"))

      learn = load_learner(os.path.join("Trained_Models", "Inpainting_FIM.pkl"))
      b1 = learn.predict(os.path.join('static', 'Test_FIM', 'original_image.jpg'))

                    # plt.imshow(b1[0].permute(1,2,0))
      final_mask = b1[0].permute(1, 2, 0)
      im_3 = t_2.ToPILImage()(np.uint8(final_mask))
      im_3.save(os.path.join('static', 'Test_FIM', 'final_mask_image_Inpainting.jpg'))

      posts = {
          'Original_Image': os.path.join('static', 'Test_FIM', 'original_image.jpg'),
          'Splicing_Image': os.path.join('static', 'Test_FIM', 'final_mask_image_Splicing.jpg'),
          'Inpainting_Image': os.path.join('static', 'Test_FIM', 'final_mask_image_Inpainting.jpg'),
          'Copy_Move_Image': os.path.join('static', 'Test_FIM', 'final_mask_image_Copy_Move.jpg'),
            }

                    # plt.show()
      #return render_template('FIM_Output.html', value=posts, filename=posts)
    else:
        a,b,c,d,e,f,g,h,i,j,k = metadata_image(image_filename)
        print("Now this is FFM")
        posts = {
            'Original_Image': image_filename,
            'label': label,
            'score': score,
            'x':a,
            'b1':b,
            'c1':c,
            'd1':d,
            'e1':e,
            'f1':f,
            'g1':g,
            'h1':h,
            'i1':i,
            'j1':j,
            'k1':k,                        
                                   
            'fake_img_path': fake_image_path
          }
                    #posts = metadata_image(filename)
       # return render_template('FFM_Output.html', value=posts, filename=posts)
    #else:
        #return redirect(request.url)
    '''          
print("Downloaded")

'''
# In case agar us download images to kisi ek folder me transfer krna ho to 
import subprocess
import os
import shutil

print("Copying start")
print("Transfering.....")
directory = ' '
subprocess.call(['chmod', '-R', '+w', '/tweet_images'])
print("permission change")
folder = "/tweet_images"
for filename in os.listdir(directory):
  if filename.endswith(".jpg") or filename.endswith(".png"):
    print(os.path.join(directory, filename))
    shutil.move(filename, folder)
  else:
      continue
print("copying done")

'''
'''
from flask import Flask, request, render_template, session, redirect
import numpy as np
import pandas as pd


app = Flask(__name__)
'''
'''
df = pd.DataFrame({'A': [0, 1, 2, 3, 4],
                   'B': [5, 6, 7, 8, 9],
                   'C': ['a', 'b', 'c--', 'd', 'e']})s

'''
'''

@app.route('/', methods=("POST", "GET"))
def html_table():

    return render_template('simple.html',  tables=[df.to_html(classes='data')], titles=df.columns.values)
'''


##########################################################################################################

###############
##########################################################################################################


##########################################################################################################




##########################################################################################################


##########################################################################################################



####################################################
#global tag_name 
#global Metainfo 

from flask import Flask, request, render_template, session, redirect
import numpy as np

import pandas as pd
print(findings)
print(scores)

df['finding'] = pd.Series(findings)
df['score'] = pd.Series(scores)

print(df)

#from flask import Flask, request, render_template, session, redirect
#import numpy as np

import pandas as pd


app = Flask(__name__)

'''
df = pd.DataFrame({'A': [0, 1, 2, 3, 4],
                   'B': [5, 6, 7, 8, 9],
                   'C': ['a', 'b', 'c--', 'd', 'e']})s

'''


@app.route('/', methods=("POST", "GET"))
def html_table():

    return render_template('simple.html',  tables=[df.to_html(classes='data')], titles=df.columns.values)




if __name__ == '__main__':
    #app.run(host='0.0.0.0')
    app.run(port=5002, debug=True)